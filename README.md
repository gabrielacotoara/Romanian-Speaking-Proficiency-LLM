# romanian-speaking-proficiency-llm
ğŸ§ª This project bridges language learning data and large language model training to improve Romanian language handling in AI systems.

# ğŸ§  Predicting Romanian Speaking Proficiency for AI & LLM Optimization

## ğŸ“Œ Project Overview  
This project explores how machine learning can predict the speaking proficiency of adult Romanian language learners using linguistic and demographic data. While itâ€™s not built for teaching Romanian, the goal is to extract patterns that can be applied in LLM training, multilingual QA, prompt design, and fairness testing in Romanian NLP tasks.

By modeling real-world learner performance, this project provides useful insights for AI trainers and prompt engineers working with Romanian or other underrepresented languages in AI systems.

## ğŸ“– Notebooks  
Explore the Jupyter notebooks in this repository:

- `model_and_insights.ipynb` â€“ Feature engineering, model building, and interpretation  
- `llm_use_cases.ipynb` â€“ Applying insights to prompt design, zero-shot tasks, and LLM evaluation  
- `sumar_in_romana.ipynb` â€“ Key results and insights in Romanian

## ğŸ”‘ Key Features Used  

- Native language and multilingual background  
- Age of arrival and length of exposure  
- Enrollment in Romanian courses  
- Language used in daily environments  

## ğŸš€ Project Workflow  

1. Load & preprocess the dataset  
2. Perform exploratory data analysis (EDA)  
3. Engineer features (categorical + numerical)  
4. Train regression models  
5. Evaluate performance (RMSE, RÂ²)  
6. Interpret results with SHAP  
7. Apply findings to LLM tasks and red teaming  

## ğŸ“Š Key Findings for LLM Work  

- Structured language learning (like formal courses) strongly improves speaking proficiency  
- Multilingual individuals outperform monolinguals in Romanian acquisition  
- Younger learners tend to reach higher proficiency faster  
- Learner metadata can improve prompt design, personalization, and output evaluation

## ğŸ¯ LLM Applications  

- Design Romanian prompts that simulate users at different fluency levels  
- Red team LLMs using realistic learner profiles  
- Evaluate fairness and accuracy for non-native Romanian speakers  
- Fine-tune multilingual models with real-world learning patterns  

## ğŸ”¬ Future Enhancements  

- Expand dataset to include broader learner groups  
- Add motivational and social features  
- Build a Romanian NLP test suite for LLMs  
- Integrate ASR data for speech-text alignment  
- Explore zero-shot and few-shot performance tuning  

## ğŸ› ï¸ Tech Stack  

**Languages & Libraries:**  
Python, pandas, NumPy, scikit-learn, SHAP, XGBoost  

**Visualization:**  
Matplotlib, Seaborn  

**ML Techniques:**  
Linear Regression, Decision Trees, Random Forest, XGBoost, Neural Networks  

**Model Evaluation:**  
RMSE, RÂ² Score, Cross-Validation  

**Deployment:**  
Flask, Pickle, OpenAI API  

## ğŸ‘¤ Maintainer  

Developed by [Irina Gabriela Cotoara Ybarra](https://github.com/gabrielacotoara)  
AI Trainer | LLM Evaluator | Romanian NLP Specialist

---

ğŸ§ª *This project bridges language learning data and large language model training to improve Romanian language handling in AI systems.*
